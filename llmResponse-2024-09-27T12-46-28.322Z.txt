```js
// App.js
import React, { useState, useEffect, useRef } from 'react';
import { StyleSheet, Text, View, TouchableOpacity, TextInput } from 'react-native';
import { Audio } from 'expo-av';
import { FontAwesome } from '@expo/vector-icons';
import axios from 'axios';
import * as Clipboard from 'expo-clipboard';

const API_URL = 'https://apihub.staging.appply.link/chatgpt';

const App = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [recording, setRecording] = useState(null);
  const [transcription, setTranscription] = useState('');
  const [timeLeft, setTimeLeft] = useState(60);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const timerRef = useRef(null);

  useEffect(() => {
    return () => {
      if (timerRef.current) clearInterval(timerRef.current);
    };
  }, []);

  const startRecording = async () => {
    try {
      const { status } = await Audio.requestPermissionsAsync();
      if (status !== 'granted') return;

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const newRecording = new Audio.Recording();
      await newRecording.prepareToRecordAsync(Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY);
      await newRecording.startAsync();

      setRecording(newRecording);
      setIsRecording(true);
      setTimeLeft(60);

      timerRef.current = setInterval(() => {
        setTimeLeft((prevTime) => {
          if (prevTime <= 1) {
            clearInterval(timerRef.current);
            stopRecording();
            return 0;
          }
          return prevTime - 1;
        });
      }, 1000);
    } catch (error) {
      console.error('Failed to start recording', error);
    }
  };

  const stopRecording = async () => {
    try {
      if (!recording) return;

      await recording.stopAndUnloadAsync();
      clearInterval(timerRef.current);
      setIsRecording(false);

      const uri = recording.getURI();
      setRecording(null);
      transcribeAudio(uri);
    } catch (error) {
      console.error('Failed to stop recording', error);
    }
  };

  const transcribeAudio = async (uri) => {
    setIsTranscribing(true);
    try {
      // In a real app, you would upload the audio file and get a transcription
      // For this example, we'll simulate the process with a delay
      await new Promise(resolve => setTimeout(resolve, 2000));

      const response = await axios.post(API_URL, {
        messages: [
          { role: "system", content: "You are a helpful assistant that transcribes audio to text." },
          { role: "user", content: "Please transcribe the following audio file." }
        ],
        model: "gpt-4o"
      });

      setTranscription(response.data.response);
    } catch (error) {
      console.error('Transcription failed', error);
      setTranscription('Transcription failed. Please try again.');
    } finally {
      setIsTranscribing(false);
    }
  };

  const copyToClipboard = async () => {
    await Clipboard.setStringAsync(transcription);
  };

  return (
    <View style={styles.container}>
      <Text style={styles.title}>Voice Transcription App</Text>
      <Text style={styles.instruction}>Press and hold the microphone to record (max 60 seconds)</Text>
      
      <TouchableOpacity
        style={styles.recordButton}
        onPressIn={startRecording}
        onPressOut={stopRecording}
      >
        <FontAwesome name="microphone" size={50} color="white" />
      </TouchableOpacity>
      
      {isRecording && (
        <View>
          <Text style={styles.timer}>{timeLeft}s</Text>
          <View style={styles.waveform}>
            {/* Simulated waveform */}
            {[...Array(10)].map((_, i) => (
              <View
                key={i}
                style={[
                  styles.waveformBar,
                  { height: Math.random() * 50 + 10 }
                ]}
              />
            ))}
          </View>
        </View>
      )}

      {isTranscribing && <Text style={styles.transcribing}>Transcribing...</Text>}

      {transcription !== '' && (
        <View style={styles.transcriptionContainer}>
          <TextInput
            style={styles.transcription}
            multiline
            value={transcription}
            onChangeText={setTranscription}
          />
          <TouchableOpacity style={styles.copyButton} onPress={copyToClipboard}>
            <Text style={styles.copyButtonText}>Copy</Text>
          </TouchableOpacity>
        </View>
      )}
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: '#f0f0f0',
    padding: 20,
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 10,
  },
  instruction: {
    fontSize: 16,
    textAlign: 'center',
    marginBottom: 20,
  },
  recordButton: {
    width: 100,
    height: 100,
    borderRadius: 50,
    backgroundColor: '#007AFF',
    justifyContent: 'center',
    alignItems: 'center',
    marginBottom: 20,
  },
  timer: {
    fontSize: 24,
    marginBottom: 10,
  },
  waveform: {
    flexDirection: 'row',
    justifyContent: 'center',
    alignItems: 'flex-end',
    height: 50,
    width: '100%',
    marginBottom: 20,
  },
  waveformBar: {
    width: 4,
    backgroundColor: '#007AFF',
    marginHorizontal: 2,
  },
  transcribing: {
    fontSize: 18,
    marginBottom: 10,
  },
  transcriptionContainer: {
    width: '100%',
  },
  transcription: {
    backgroundColor: 'white',
    borderRadius: 5,
    padding: 10,
    minHeight: 100,
    textAlignVertical: 'top',
  },
  copyButton: {
    backgroundColor: '#007AFF',
    padding: 10,
    borderRadius: 5,
    marginTop: 10,
    alignSelf: 'flex-end',
  },
  copyButtonText: {
    color: 'white',
    fontWeight: 'bold',
  },
});

export default App;
// End of App.js
```